{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a1b193e-b5ce-4ff7-9d0e-f43c16d5d458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# print(torch.cuda.is_available())\n",
    "# print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0752a174-a9dd-4ee2-9088-e188d11904b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.18.7-py3-none-win_amd64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\alex\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (2.5.1+cu118)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (4.25.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.19.0-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.4-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from wandb) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\alex\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 5.2/10.0 MB 31.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 34.8 MB/s eta 0:00:00\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Downloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
      "Downloading wandb-0.18.7-py3-none-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 9.4/15.5 MB 45.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 42.4 MB/s eta 0:00:00\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "Downloading sentry_sdk-2.19.0-py2.py3-none-any.whl (322 kB)\n",
      "Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 27.2 MB/s eta 0:00:00\n",
      "Downloading setproctitle-1.3.4-cp312-cp312-win_amd64.whl (12 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, setproctitle, sentry-sdk, safetensors, multiprocess, docker-pycreds, huggingface-hub, wandb, tokenizers, accelerate, transformers, datasets\n",
      "Successfully installed accelerate-1.1.1 datasets-3.1.0 docker-pycreds-0.4.0 huggingface-hub-0.26.2 multiprocess-0.70.16 safetensors-0.4.5 sentry-sdk-2.19.0 setproctitle-1.3.4 tokenizers-0.20.3 transformers-4.46.3 wandb-0.18.7 xxhash-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\Alex\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts wandb.exe and wb.exe are installed in 'C:\\Users\\Alex\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts accelerate-config.exe, accelerate-estimate-memory.exe, accelerate-launch.exe, accelerate-merge-weights.exe and accelerate.exe are installed in 'C:\\Users\\Alex\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\Alex\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script datasets-cli.exe is installed in 'C:\\Users\\Alex\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers datasets accelerate wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c27bcda-7226-48a9-bbbd-a22a7cb74105",
   "metadata": {},
   "source": [
    "__Get the dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c482b6ea-af41-4756-8f20-4f71405d49b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 30 16:02:26 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 556.12                 Driver Version: 556.12         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   35C    P0             25W /  115W |       0MiB /   6144MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b7bc9a-07f9-4501-9932-ad251bef490b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify gpu for torch\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46292aa3-8c2b-4c69-9d86-f3b544e8113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", '3.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fea525c-dcb3-4e57-b6b6-1a0d23a17b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f1ae2c-d4a6-46a7-bf8f-ffe563f3c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\[[^\\]]*\\]', '', text)\n",
    "    return text\n",
    "dataset = dataset.map(lambda x: {'article': clean_text(x['article'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7529bd9-5e87-466d-9724-353bf1fcead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into **training** and **validation** sets.\n",
    "\n",
    "train_test_data = dataset['train'].train_test_split(test_size=0.1)\n",
    "train_data = train_test_data['train']\n",
    "val_data = train_test_data['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ba3586b-1ced-4209-ba6e-317784a33d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b586e9b8ba4682974f3d9bdd469554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Alex\\.cache\\huggingface\\hub\\models--google-t5--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5de30536d94d078611f7f1eba30975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb55f9a284bf47b4972c033df4519521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221e72c1958b45f691c89720d04172b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/258401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177fe2d730744feb827e498f6e815635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e822c86fa0d4892a5d251cdb8d79ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/258401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a93c3dc92554320a33ea80e8451b63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "#   return tokenizer(examples[\"article\"], max_length=1024, truncation=True)\n",
    "\n",
    "#tokenized_data = train_data.map(tokenize_function, batched=True)\n",
    "# Assuming `tokenizer` is initialized\n",
    "\n",
    "# max_length=1024\n",
    "max_length=512\n",
    "\n",
    "train_data = train_data.map(lambda x: tokenizer(x['article'], padding='max_length', truncation=True, max_length=max_length), batched=True)\n",
    "val_data = val_data.map(lambda x: tokenizer(x['article'], padding='max_length', truncation=True, max_length=max_length), batched=True)\n",
    "\n",
    "# Set the labels for the model (if needed, e.g., for summarization)\n",
    "train_data = train_data.map(lambda x: {'labels': tokenizer(x['highlights'], padding='max_length', truncation=True, max_length=max_length)['input_ids']})\n",
    "val_data = val_data.map(lambda x: {'labels': tokenizer(x['highlights'], padding='max_length', truncation=True, max_length=max_length)['input_ids']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d64643c7-14e6-463a-8146-c3057628ad15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 258401\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cc5a585-6dc1-4092-bb94-5101d31015e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "my_object_512 = {'trainData': train_data, 'valData': val_data}\n",
    "\n",
    "with open('my_object_512.pkl', 'wb') as f:\n",
    "    pickle.dump(my_object_512, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b7c92af-0e38-43a2-8200-92b79c9d199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose a Pre-trained Model - Use a pre-trained model like `BART`, `T5`, or `Pegasus` for summarization: pretrain on datasets, last layer retrain,\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# smaller model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1077800-1887-4631-bc08-1ca23d8d31e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: agscheue (agscheue-umich). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Alex\\Documents\\MS_SW\\ECE-5831\\project\\wandb\\run-20241130_162126-6l2ykc8n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/agscheue-umich/huggingface/runs/6l2ykc8n' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/agscheue-umich/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/agscheue-umich/huggingface' target=\"_blank\">https://wandb.ai/agscheue-umich/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/agscheue-umich/huggingface/runs/6l2ykc8n' target=\"_blank\">https://wandb.ai/agscheue-umich/huggingface/runs/6l2ykc8n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='193803' max='193803' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [193803/193803 17:43:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.291600</td>\n",
       "      <td>0.266130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.296600</td>\n",
       "      <td>0.264532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.296700</td>\n",
       "      <td>0.264025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=193803, training_loss=0.2981521848865768, metrics={'train_runtime': 63798.7488, 'train_samples_per_second': 12.151, 'train_steps_per_second': 3.038, 'total_flos': 1.0491737052649882e+17, 'train_loss': 0.2981521848865768, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Model: Fine-tune the model using your dataset. Hugging Face’s 'Trainer' API simplifies the process:\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01\n",
    "    )\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./results/t5-small\",  # Save directory\n",
    "#     evaluation_strategy=\"epoch\",     # Evaluate at each epoch\n",
    "#     learning_rate=5e-5,              # Adjusted learning rate\n",
    "#     per_device_train_batch_size=8,   # Batch size per device\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     num_train_epochs=3,              # Number of epochs\n",
    "#     weight_decay=0.01,               # Regularization\n",
    "#     save_strategy=\"epoch\",           # Save checkpoint at each epoch\n",
    "#     save_total_limit=2,              # Keep only 2 checkpoints\n",
    "#     logging_dir=\"./logs\",            # Log directory\n",
    "#     logging_steps=200,               # Log every 200 steps\n",
    "# )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    )\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce730b24-0702-4475-aa7f-d3db1b7d27ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./T5-ai-model\\\\tokenizer_config.json',\n",
       " './T5-ai-model\\\\special_tokens_map.json',\n",
       " './T5-ai-model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save model\n",
    "model.save_pretrained(\"./T5-ai-model\")\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained('./T5-ai-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d1096-4748-4924-812b-41d55ec20dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
